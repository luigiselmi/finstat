{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2b1045ca-fb97-45d3-9772-8a71fafb52ff",
      "metadata": {
        "id": "2b1045ca-fb97-45d3-9772-8a71fafb52ff"
      },
      "source": [
        "# Ch.13 Bayesian statistics\n",
        "The goal of a statistical analysis of a process is to figure out what are the variables that play a role and the relationships between them. Usually the observations have a random component. We might have a model of the process, for example we might start with two variables: one dependent variable y and one independent variable x. We might make two additional assumptions: the relationship between y and x is linear and the random compnent is normally distributed. The next step is to assess our assumptions using a sample of observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88555a6b-cabc-457d-b920-93241e1ab95d",
      "metadata": {
        "id": "88555a6b-cabc-457d-b920-93241e1ab95d"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import scipy.stats as scs\n",
        "import scipy.optimize as sco\n",
        "from scipy import interpolate\n",
        "import pymc as pm\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from pylab import plt, mpl\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print('Matplotlib version: {}'.format(mpl.__version__))\n",
        "print('NumPy version: {}'.format(np.__version__))\n",
        "print('Pandas version: {}'.format(pd.__version__))\n",
        "print('PyMC version: {}'.format(pm.__version__))\n",
        "print('Statsmodels version: {}'.format(sm.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b5f9c8-ef5b-4d2e-8f50-0bcd95bdedb6",
      "metadata": {
        "id": "b3b5f9c8-ef5b-4d2e-8f50-0bcd95bdedb6"
      },
      "source": [
        "We can simulate a linear process by sampling the random component from a standard distribution with mean=0 and standard deviation std=1\n",
        "\n",
        "$$y = a + bx + \\epsilon$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68908964-f057-4dc6-b626-a904793aa22f",
      "metadata": {
        "id": "68908964-f057-4dc6-b626-a904793aa22f"
      },
      "outputs": [],
      "source": [
        "size = 500\n",
        "x = np.linspace(0, 10, size)\n",
        "y = 4 + 2 * x + np.random.standard_normal(size) * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbba4799-51f9-4142-802a-e19173cbc60e",
      "metadata": {
        "id": "fbba4799-51f9-4142-802a-e19173cbc60e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, c=y, marker='v', cmap='coolwarm')\n",
        "plt.colorbar()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee29381-3106-465e-b317-7655f127541f",
      "metadata": {
        "id": "fee29381-3106-465e-b317-7655f127541f"
      },
      "source": [
        "## Ordinary least squares\n",
        "Now we can fit the simulated data using the [NumPy Polynomial.fit()](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html) method that performs a polynomial fit using the least squares method. Since we assume the relationship is linear we set the degree of the polynomial to 1. The method returns the coefficients of the polynomial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e29b6ff3-a68b-4636-9a0f-6f48f845bb12",
      "metadata": {
        "id": "e29b6ff3-a68b-4636-9a0f-6f48f845bb12"
      },
      "outputs": [],
      "source": [
        "from numpy.polynomial import Polynomial\n",
        "reg = Polynomial.fit(x, y, deg=1)\n",
        "reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6cb8fa2-9ded-40ec-8eab-57f760829f77",
      "metadata": {
        "id": "b6cb8fa2-9ded-40ec-8eab-57f760829f77"
      },
      "outputs": [],
      "source": [
        "a = reg.convert().coef[0]\n",
        "b = reg.convert().coef[1]\n",
        "print('Linear coefficients\\na={:.2f}\\nb={:.2f}'.format(a, b))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6B_FIlBqkm8",
      "metadata": {
        "id": "e6B_FIlBqkm8"
      },
      "source": [
        "We plot the linear fit to the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf2fe63-89ee-4f6e-aa28-7d6fe2362da9",
      "metadata": {
        "id": "cbf2fe63-89ee-4f6e-aa28-7d6fe2362da9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, c=y, marker='v', cmap='coolwarm')\n",
        "y_fit = a + b * x\n",
        "plt.plot(x, y_fit, lw=2.0)\n",
        "plt.colorbar()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uYNwXWFXhu4Z",
      "metadata": {
        "id": "uYNwXWFXhu4Z"
      },
      "source": [
        "## Bayes theorem\n",
        "The coefficient a and b are not fixed values, they come with an associated error that can be estimated with a certain degree of confidence or accuracy. We can use the Bayesian approach to calculate the standard error of the two coefficients. Before that we discuss briefly the theory behind the Bayes theorem. Bayes' theorem is based on the multiplication theorem that can be stated as\n",
        "\n",
        "$$P(H|D)P(D) = P(D|H)P(D)$$\n",
        "\n",
        "so that\n",
        "\n",
        "$$P(H|D) = \\frac{P(D|H)P(H)}{P(D)}$$\n",
        "\n",
        "where the probabilities have the following interpretation\n",
        "\n",
        "* The hypothesis, or prior probability, P(H)\n",
        "* The likelihood, or probability for the observations given the initial hypothesis, P(D|H)\n",
        "* The posterivion probability, given the observations, P(H|D)\n",
        "* The total probability of the observations, P(D)\n",
        "\n",
        "In our example we assume the hypothesis that the coefficients a and b are normally distributed and independent with zero mean value and variance in [0, 20.0] and [0, 10.0] respectively, that is our prior is\n",
        "\n",
        "$$P(H) = P(a,b) = P(a)P(b) = N(0, \\sigma_a)N(0, \\sigma_b)$$\n",
        "\n",
        "For the likelihood we assume that the y(x) values are also normally distributed with mean value $\\overline{y}$, calculated from the observations, and a variance $\\sigma$ that we assume uniformly distributed in [0, 10.0]\n",
        "\n",
        "$$P(D|H) = N(\\overline{y}, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{\\frac{1}{2}(\\frac{y - \\overline{y}}{\\sigma})^2}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\\sigma = U(0, 10.0)$$\n",
        "\n",
        "We use [PyMC](https://www.pymc.io/) to build the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d094d1a-7058-4b58-87a1-0ecfc951b06b",
      "metadata": {
        "id": "2d094d1a-7058-4b58-87a1-0ecfc951b06b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "with pm.Model() as model:\n",
        "  # model\n",
        "  a = pm.Normal('a', mu=0, sigma=20)\n",
        "  b = pm.Normal('b', mu=0, sigma=10)\n",
        "  sigma = pm.Uniform('sigma', lower=0, upper=10)\n",
        "  y_est = a + b * x\n",
        "  likelihood = pm.Normal('y', mu=y_est, sigma=sigma, observed=y)\n",
        "  # inference\n",
        "  start = pm.find_MAP()\n",
        "  step = pm.NUTS()\n",
        "  trace = pm.sample(100, tune=1000, start=start, progressbar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7PIol5LxQXep",
      "metadata": {
        "id": "7PIol5LxQXep"
      },
      "outputs": [],
      "source": [
        "pm.summary(trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nm-F-HbtGOP8",
      "metadata": {
        "id": "Nm-F-HbtGOP8"
      },
      "source": [
        "The sampler generates a number of parallel chains with the results for the parameters depending on the number of cores available. The values in the chains can be used together by flattening the array in one single dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-QTzdrcqQ_eK",
      "metadata": {
        "id": "-QTzdrcqQ_eK"
      },
      "outputs": [],
      "source": [
        "trace['posterior']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MNZiZwdARD-9",
      "metadata": {
        "id": "MNZiZwdARD-9"
      },
      "outputs": [],
      "source": [
        "pm.plot_trace(trace, lines={'alpha': 4, 'beta': 2, 'sigma': 2});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Ja3PJrLRpRS",
      "metadata": {
        "id": "2Ja3PJrLRpRS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, c=y, marker='v', cmap='coolwarm')\n",
        "#plt.colorbar()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# Access the posterior samples for 'a' and 'b' and flatten them\n",
        "a_samples = trace.posterior.a.values.flatten()\n",
        "b_samples = trace.posterior.b.values.flatten()\n",
        "\n",
        "# Iterate through each sample and plot the corresponding line\n",
        "for i in range(len(a_samples)):\n",
        "  y_sampled = a_samples[i] + b_samples[i] * x\n",
        "  plt.plot(x, y_sampled, color='gray', alpha=0.1) # Plot with some transparency\n",
        "\n",
        "# Optionally, plot the mean Bayesian fit\n",
        "mean_a = a_samples.mean()\n",
        "mean_b = b_samples.mean()\n",
        "y_mean_fit = mean_a + mean_b * x\n",
        "plt.plot(x, y_mean_fit, color='red', lw=2.0, label='Mean Bayesian Fit')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04dff6d2-5fc9-42e1-b657-bd8e4f93433f",
      "metadata": {
        "id": "04dff6d2-5fc9-42e1-b657-bd8e4f93433f"
      },
      "outputs": [],
      "source": [
        "raw = pd.read_csv('source/tr_eikon_eod_data.csv', index_col=0, parse_dates=True)\n",
        "data = raw[['GDX', 'GLD']].dropna()\n",
        "data = data / data.iloc[0]\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0886e1e9-d753-44e2-9662-35692cd36327",
      "metadata": {
        "id": "0886e1e9-d753-44e2-9662-35692cd36327"
      },
      "outputs": [],
      "source": [
        "data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e6379e-fc5e-477d-a193-ff4fc0a0a5b9",
      "metadata": {
        "id": "11e6379e-fc5e-477d-a193-ff4fc0a0a5b9"
      },
      "outputs": [],
      "source": [
        "data.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d53f1503-5e2f-4195-b98a-42174ceb57fb",
      "metadata": {
        "id": "d53f1503-5e2f-4195-b98a-42174ceb57fb"
      },
      "outputs": [],
      "source": [
        "data.plot(figsize=(10, 6));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2641414a-29cd-4177-93c2-9ddbf53e03c3",
      "metadata": {
        "id": "2641414a-29cd-4177-93c2-9ddbf53e03c3"
      },
      "source": [
        "## Updating estimates over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "760870f2-9569-40f3-a763-6bea7b867412",
      "metadata": {
        "id": "760870f2-9569-40f3-a763-6bea7b867412"
      },
      "outputs": [],
      "source": [
        "mpl_dates = mpl.dates.date2num(data.index.to_pydatetime())\n",
        "mpl_dates[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "280c71fb-eb1f-4967-b6dc-7779afe3b45e",
      "metadata": {
        "id": "280c71fb-eb1f-4967-b6dc-7779afe3b45e"
      },
      "outputs": [],
      "source": [
        "from pymc.distributions.timeseries import GaussianRandomWalk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f60270f-e103-42b1-841c-669edcc80199",
      "metadata": {
        "id": "8f60270f-e103-42b1-841c-669edcc80199"
      },
      "outputs": [],
      "source": [
        "subsample_alpha = 50\n",
        "subsample_beta = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e0a133-22dd-4773-b835-96a61a718fb5",
      "metadata": {
        "id": "38e0a133-22dd-4773-b835-96a61a718fb5"
      },
      "outputs": [],
      "source": [
        "model_randomwalk = pm.Model()\n",
        "with model_randomwalk:\n",
        "    sigma_alpha = pm.Exponential('sig_alpha', 1. / .02, initval=.1)\n",
        "    sigma_beta = pm.Exponential('sig_beta', 1. / .02, initval=.1)\n",
        "    alpha = GaussianRandomWalk('alpha', sigma_alpha ** -2, shape=int(len(data) / subsample_alpha))\n",
        "    beta = GaussianRandomWalk('beta', sigma_beta ** -2, shape=int(len(data) / subsample_beta))\n",
        "    alpha_r = np.repeat(alpha, subsample_alpha)\n",
        "    beta_r = np.repeat(beta, subsample_beta)\n",
        "    regression = alpha_r + beta_r * data['GDX'].values[:2100]\n",
        "    sd = pm.Uniform('sigma', 0, 20)\n",
        "    likelihood = pm.Normal('GLD', mu=regression, sigma=sd, observed=data['GLD'].values[:2100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e923957-a019-4174-ae91-f631d7351dd1",
      "metadata": {
        "id": "3e923957-a019-4174-ae91-f631d7351dd1"
      },
      "outputs": [],
      "source": [
        "with model_randomwalk:\n",
        "    start = pm.find_MAP(vars=[alpha, beta])\n",
        "    step = pm.NUTS()\n",
        "    trace_rw = pm.sample(250, tune=1000, start=start, progressbar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb45554-d84f-432d-8b15-40654e12b555",
      "metadata": {
        "id": "cfb45554-d84f-432d-8b15-40654e12b555"
      },
      "outputs": [],
      "source": [
        "pm.summary(trace_rw).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98cb7c71-8e5e-4bdf-95ff-22de5230a1a2",
      "metadata": {
        "id": "98cb7c71-8e5e-4bdf-95ff-22de5230a1a2"
      },
      "outputs": [],
      "source": [
        "trace_rw['posterior']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc539aa9-cdab-4f6a-a51c-bff6b124135a",
      "metadata": {
        "id": "cc539aa9-cdab-4f6a-a51c-bff6b124135a"
      },
      "outputs": [],
      "source": [
        "sh = np.shape(trace_rw['posterior']['alpha'])\n",
        "sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8edd7acc-e44b-4dc7-84dc-ecc1381dea1a",
      "metadata": {
        "id": "8edd7acc-e44b-4dc7-84dc-ecc1381dea1a"
      },
      "outputs": [],
      "source": [
        "part_dates = np.linspace(min(mpl_dates), max(mpl_dates), sh[1])\n",
        "part_dates[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bb8152-2987-4cfd-8952-64f1269b16c4",
      "metadata": {
        "id": "76bb8152-2987-4cfd-8952-64f1269b16c4"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "#index = [date.fromordinal(int(date)) for date in part_dates]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074ed9dc-0ab1-4dc4-b5b5-e320de4217c9",
      "metadata": {
        "id": "074ed9dc-0ab1-4dc4-b5b5-e320de4217c9"
      },
      "outputs": [],
      "source": [
        "alpha = {'alpha_%i' % i: v for i, v in enumerate(trace_rw['posterior']['alpha']) if i < 20}\n",
        "alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f60afd2-7d1c-4d38-833a-a6afd877b60c",
      "metadata": {
        "id": "8f60afd2-7d1c-4d38-833a-a6afd877b60c"
      },
      "outputs": [],
      "source": [
        "df_alpha = pd.DataFrame(alpha['alpha_0'], index=data.index[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570b5219-e2a7-47ad-a560-01d5777e641e",
      "metadata": {
        "id": "570b5219-e2a7-47ad-a560-01d5777e641e"
      },
      "outputs": [],
      "source": [
        "beta = {'beta_%i' % i: v for i, v in enumerate(trace_rw['posterior']['beta']) if i < 20}\n",
        "beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b591955-c36f-4337-aeec-e7ddc8433fa5",
      "metadata": {
        "id": "5b591955-c36f-4337-aeec-e7ddc8433fa5"
      },
      "outputs": [],
      "source": [
        "df_beta = pd.DataFrame(beta['beta_0'], index=data.index[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da28096-abfe-4dde-afbd-883fc9b0e768",
      "metadata": {
        "id": "1da28096-abfe-4dde-afbd-883fc9b0e768"
      },
      "outputs": [],
      "source": [
        "ax = df_alpha.plot(color='b', style='-.', legend=False, lw=0.7, figsize=(10, 6))\n",
        "df_beta.plot(color='r', style='-.', legend=False, lw=0.7, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dc3dc44-59a2-411e-97b7-d9d34ef4f784",
      "metadata": {
        "id": "1dc3dc44-59a2-411e-97b7-d9d34ef4f784"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}